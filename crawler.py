import requests
import os
import json
from datetime import datetime
from supabase import create_client
from openai import OpenAI
import re
import time

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
SEARCH_KEYWORDS = [
    "ì•„ì´í° 15",
    "ê°¤ëŸ­ì‹œ S24", 
    "ë§¥ë¶ í”„ë¡œ",
    "ì—ì–´íŒŸ í”„ë¡œ"
]

def generate_embedding(text):
    """í…ìŠ¤íŠ¸ì—ì„œ OpenAI ì„ë² ë”© ìƒì„±"""
    try:
        response = openai_client.embeddings.create(
            input=text,
            model="text-embedding-3-small"
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def clean_html_tags(text):
    """HTML íƒœê·¸ ì œê±°"""
    if not text:
        return ""
    return re.sub(r'<.*?>', '', text)

def search_naver_shopping(keyword, display=50, sort="sim"):
    """ë„¤ì´ë²„ ì‡¼í•‘ API ê²€ìƒ‰"""
    url = "https://openapi.naver.com/v1/search/shop.json"
    
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    
    params = {
        "query": keyword,
        "display": display,
        "sort": sort
    }
    
    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"API ìš”ì²­ ì˜¤ë¥˜ ({keyword}): {e}")
        return None

def check_duplicate_by_url(url):
    """URLë¡œ ì¤‘ë³µ ìƒí’ˆ í™•ì¸"""
    try:
        # metadataì—ì„œ url í•„ë“œë¡œ ì¤‘ë³µ í™•ì¸
        result = supabase.table('documents').select('id').eq('metadata->>url', url).execute()
        return len(result.data) > 0
    except Exception as e:
        print(f"ì¤‘ë³µ í™•ì¸ ì˜¤ë¥˜: {e}")
        return False

def save_to_supabase(items, keyword):
    """Supabaseì— ìƒí’ˆ ë°ì´í„° ì €ì¥"""
    saved_count = 0
    skipped_count = 0
    
    for item in items:
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        title = clean_html_tags(item.get('title', ''))
        description = clean_html_tags(item.get('description', ''))
        product_url = item.get('link', '')
        
        # ì¤‘ë³µ í™•ì¸ (URL ê¸°ì¤€)
        if check_duplicate_by_url(product_url):
            skipped_count += 1
            continue
        
        # content í•„ë“œ ìƒì„± (ì œëª© + ì„¤ëª…)
        content = f"{title} {description}".strip()
        
        # ê°€ê²© ì •ë³´ ì²˜ë¦¬
        lprice = item.get('lprice', '')
        hprice = item.get('hprice', '')
        
        try:
            lprice = int(lprice) if lprice else None
            hprice = int(hprice) if hprice else None
        except (ValueError, TypeError):
            lprice = None
            hprice = None
        
        # metadata í•„ë“œ êµ¬ì„± (JSONB í˜•íƒœ)
        metadata = {
            "title": title,
            "description": description,
            "url": product_url,
            "search_keyword": keyword,
            "source": "naver_shopping",
            "collected_at": datetime.now().isoformat(),
            "price": {
                "lprice": lprice,  # ìµœì €ê°€
                "hprice": hprice   # ìµœê³ ê°€
            },
            "product_info": {
                "productId": item.get('productId', ''),
                "productType": item.get('productType', ''),
                "maker": item.get('maker', ''),
                "brand": item.get('brand', ''),
                "category1": item.get('category1', ''),
                "category2": item.get('category2', ''),
                "category3": item.get('category3', ''),
                "category4": item.get('category4', '')
            },
            "mall_info": {
                "mallName": item.get('mallName', ''),
                "image": item.get('image', '')
            }
        }
        
        # ì„ë² ë”© ìƒì„±
        embedding = generate_embedding(content)
        if not embedding:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ë¡œ ìŠ¤í‚µ: {title[:30]}...")
            continue
        
        # Supabaseì— ë°ì´í„° ì‚½ì…
        try:
            insert_data = {
                'content': content,
                'metadata': metadata,
                'embedding': embedding
            }
            
            result = supabase.table('documents').insert(insert_data).execute()
            
            if result.data:
                saved_count += 1
                print(f"âœ… ì €ì¥ì™„ë£Œ: {title[:50]}...")
            else:
                print(f"âŒ ì €ì¥ì‹¤íŒ¨: {title[:30]}...")
                
        except Exception as e:
            print(f"ì €ì¥ ì˜¤ë¥˜: {e}")
            print(f"ì‹¤íŒ¨í•œ ìƒí’ˆ: {title[:30]}...")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
        time.sleep(0.1)
    
    return saved_count, skipped_count

def get_database_stats():
    """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´"""
    try:
        # ì „ì²´ ë¬¸ì„œ ìˆ˜
        total_result = supabase.table('documents').select('id', count='exact').execute()
        total_count = total_result.count if hasattr(total_result, 'count') else len(total_result.data)
        
        # ë„¤ì´ë²„ ì‡¼í•‘ ë°ì´í„° ìˆ˜
        shopping_result = supabase.table('documents').select('id', count='exact').eq('metadata->>source', 'naver_shopping').execute()
        shopping_count = shopping_result.count if hasattr(shopping_result, 'count') else len(shopping_result.data)
        
        return total_count, shopping_count
    except Exception as e:
        print(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None, None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print(f"ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ í¬ë¡¤ë§ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_vars = [NAVER_CLIENT_ID, NAVER_CLIENT_SECRET, SUPABASE_URL, SUPABASE_KEY, OPENAI_API_KEY]
    if not all(required_vars):
        print("âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    total_saved = 0
    total_skipped = 0
    
    # ì‹œì‘ ì „ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
    before_total, before_shopping = get_database_stats()
    if before_total is not None:
        print(f"ğŸ“Š ì‹œì‘ ì „ DB ìƒíƒœ - ì „ì²´: {before_total}ê°œ, ì‡¼í•‘: {before_shopping}ê°œ")
    
    # ê° í‚¤ì›Œë“œë³„ í¬ë¡¤ë§
    for i, keyword in enumerate(SEARCH_KEYWORDS, 1):
        print(f"\nğŸ” [{i}/{len(SEARCH_KEYWORDS)}] '{keyword}' ê²€ìƒ‰ ì¤‘...")
        
        # ë„¤ì´ë²„ ì‡¼í•‘ API í˜¸ì¶œ
        result = search_naver_shopping(keyword, display=100)
        
        if not result or 'items' not in result:
            print(f"âŒ '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            continue
        
        items = result['items']
        print(f"ğŸ“¦ '{keyword}': {len(items)}ê°œ ìƒí’ˆ ë°œê²¬")
        
        # Supabaseì— ì €ì¥
        saved, skipped = save_to_supabase(items, keyword)
        total_saved += saved
        total_skipped += skipped
        
        print(f"âœ… '{keyword}' ì²˜ë¦¬ì™„ë£Œ: {saved}ê°œ ì €ì¥, {skipped}ê°œ ì¤‘ë³µìŠ¤í‚µ")
        
        # API ìš”ì²­ ê°„ê²©
        if i < len(SEARCH_KEYWORDS):
            time.sleep(2)
    
    # ì™„ë£Œ í›„ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
    after_total, after_shopping = get_database_stats()
    
    print(f"\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ˆ ê²°ê³¼ ìš”ì•½:")
    print(f"   - ìƒˆë¡œ ì €ì¥: {total_saved}ê°œ")
    print(f"   - ì¤‘ë³µ ìŠ¤í‚µ: {total_skipped}ê°œ")
    
    if after_total is not None and before_total is not None:
        print(f"ğŸ“Š DB ìƒíƒœ ë³€í™”:")
        print(f"   - ì „ì²´ ë¬¸ì„œ: {before_total} â†’ {after_total} (+{after_total - before_total})")
        print(f"   - ì‡¼í•‘ ë°ì´í„°: {before_shopping} â†’ {after_shopping} (+{after_shopping - before_shopping})")

if __name__ == "__main__":
    main()
